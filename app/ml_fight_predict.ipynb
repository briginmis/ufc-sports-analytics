{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_avg_SIG_STR_landed</th>\n",
       "      <th>B_avg_SIG_STR_pct</th>\n",
       "      <th>B_avg_SUB_ATT</th>\n",
       "      <th>B_avg_TD_landed</th>\n",
       "      <th>B_avg_TD_pct</th>\n",
       "      <th>B_longest_win_streak</th>\n",
       "      <th>...</th>\n",
       "      <th>R_wins</th>\n",
       "      <th>R_Stance</th>\n",
       "      <th>R_Height_cms</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_age</th>\n",
       "      <th>B_age</th>\n",
       "      <th>B_winratio</th>\n",
       "      <th>R_winratio</th>\n",
       "      <th>B_totalfights</th>\n",
       "      <th>R_totalfights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>187.96</td>\n",
       "      <td>193.04</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.160000</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>180.34</td>\n",
       "      <td>193.04</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>190.50</td>\n",
       "      <td>195.58</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>175.26</td>\n",
       "      <td>182.88</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.220000</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>175.26</td>\n",
       "      <td>177.80</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>182.88</td>\n",
       "      <td>182.88</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>170.18</td>\n",
       "      <td>177.80</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>187.96</td>\n",
       "      <td>195.58</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>193.04</td>\n",
       "      <td>198.12</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>Blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>190.50</td>\n",
       "      <td>190.50</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3674 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Winner  B_current_lose_streak  B_current_win_streak  B_draw  \\\n",
       "0       Red                      0                     1       0   \n",
       "1      Blue                      2                     0       0   \n",
       "2      Blue                      1                     0       0   \n",
       "3       Red                      1                     0       0   \n",
       "4      Blue                      0                     2       0   \n",
       "...     ...                    ...                   ...     ...   \n",
       "4888    Red                      1                     0       0   \n",
       "4889    Red                      1                     0       0   \n",
       "4890   Blue                      0                     1       0   \n",
       "4893    Red                      1                     0       0   \n",
       "4895   Blue                      1                     0       0   \n",
       "\n",
       "      B_avg_SIG_STR_landed  B_avg_SIG_STR_pct  B_avg_SUB_ATT  B_avg_TD_landed  \\\n",
       "0                 3.420000             0.5900       0.700000         0.240000   \n",
       "1                 5.160000             0.4200       0.800000         0.790000   \n",
       "2                 2.920000             0.4100       0.100000         1.150000   \n",
       "3                 4.040000             0.3400       0.000000         0.000000   \n",
       "4                 5.220000             0.5600       0.000000         2.540000   \n",
       "...                    ...                ...            ...              ...   \n",
       "4888              5.250000             0.5550       0.125000         0.000000   \n",
       "4889             10.750000             0.3325       1.250000         1.250000   \n",
       "4890             22.166667             0.5100       0.166667         2.500000   \n",
       "4893              8.000000             0.3400       1.000000         1.000000   \n",
       "4895             31.666667             0.4600       0.666667         1.666667   \n",
       "\n",
       "      B_avg_TD_pct  B_longest_win_streak  ...  R_wins  R_Stance  R_Height_cms  \\\n",
       "0           1.0000                     4  ...      13  Orthodox        187.96   \n",
       "1           0.2200                     2  ...      11  Orthodox        180.34   \n",
       "2           0.3400                     5  ...       6  Orthodox        190.50   \n",
       "3           0.0000                     0  ...       4  Orthodox        175.26   \n",
       "4           0.3900                     2  ...       4  Orthodox        175.26   \n",
       "...            ...                   ...  ...     ...       ...           ...   \n",
       "4888        0.0000                     2  ...       5  Orthodox        182.88   \n",
       "4889        0.6625                     1  ...       5  Orthodox        170.18   \n",
       "4890        0.4800                     2  ...       3  Orthodox        187.96   \n",
       "4893        1.0000                     0  ...       0  Orthodox        193.04   \n",
       "4895        0.5000                     2  ...       3  Orthodox        190.50   \n",
       "\n",
       "      R_Reach_cms  R_age  B_age  B_winratio  R_winratio  B_totalfights  \\\n",
       "0          193.04     37     29    0.714286    0.619048              7   \n",
       "1          193.04     33     32    0.545455    0.578947             11   \n",
       "2          195.58     34     32    0.642857    0.600000             14   \n",
       "3          182.88     29     32    0.000000    0.571429              1   \n",
       "4          177.80     28     33    0.625000    1.000000              8   \n",
       "...           ...    ...    ...         ...         ...            ...   \n",
       "4888       182.88     28     31    0.500000    0.500000              8   \n",
       "4889       177.80     28     28    0.500000    0.500000              4   \n",
       "4890       195.58     29     39    0.666667    1.000000              6   \n",
       "4893       198.12     27     27    0.000000    0.000000              1   \n",
       "4895       190.50     32     34    0.666667    0.500000              3   \n",
       "\n",
       "      R_totalfights  \n",
       "0                21  \n",
       "1                19  \n",
       "2                10  \n",
       "3                 7  \n",
       "4                 4  \n",
       "...             ...  \n",
       "4888             10  \n",
       "4889             10  \n",
       "4890              3  \n",
       "4893              1  \n",
       "4895              6  \n",
       "\n",
       "[3674 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read predict data\n",
    "predict_data = pd.read_csv(\"resources/predict_data.csv\", index_col=0)\n",
    "\n",
    "predict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data for machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X (data) and y (target)\n",
    "X = predict_data.drop(\"Winner\", axis=1)\n",
    "y = predict_data[\"Winner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['B_current_lose_streak', 'B_current_win_streak', 'B_draw',\n",
       "       'B_avg_SIG_STR_landed', 'B_avg_SIG_STR_pct', 'B_avg_SUB_ATT',\n",
       "       'B_avg_TD_landed', 'B_avg_TD_pct', 'B_longest_win_streak', 'B_losses',\n",
       "       'B_total_rounds_fought', 'B_total_title_bouts',\n",
       "       'B_win_by_Decision_Majority', 'B_win_by_Decision_Split',\n",
       "       'B_win_by_Decision_Unanimous', 'B_win_by_KO/TKO', 'B_win_by_Submission',\n",
       "       'B_win_by_TKO_Doctor_Stoppage', 'B_wins', 'B_Height_cms', 'B_Reach_cms',\n",
       "       'R_current_lose_streak', 'R_current_win_streak', 'R_draw',\n",
       "       'R_avg_SIG_STR_landed', 'R_avg_SIG_STR_pct', 'R_avg_SUB_ATT',\n",
       "       'R_avg_TD_landed', 'R_avg_TD_pct', 'R_longest_win_streak', 'R_losses',\n",
       "       'R_total_rounds_fought', 'R_total_title_bouts',\n",
       "       'R_win_by_Decision_Majority', 'R_win_by_Decision_Split',\n",
       "       'R_win_by_Decision_Unanimous', 'R_win_by_KO/TKO', 'R_win_by_Submission',\n",
       "       'R_win_by_TKO_Doctor_Stoppage', 'R_wins', 'R_Height_cms', 'R_Reach_cms',\n",
       "       'R_age', 'B_age', 'B_winratio', 'R_winratio', 'B_totalfights',\n",
       "       'R_totalfights', 'B_Stance_Open Stance', 'B_Stance_Orthodox',\n",
       "       'B_Stance_Southpaw', 'B_Stance_Switch', 'R_Stance_Open Stance',\n",
       "       'R_Stance_Orthodox', 'R_Stance_Southpaw', 'R_Stance_Switch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Pandas get_dummies to convert categorical data\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform the training and testing data using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model using training data\n",
    "classifier.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.26 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score and predict target values\n",
    "score = classifier.score(X_test_scaled, encoded_y_test)\n",
    "print(\"Accuracy: {0:.2f} %\".format(100 * score))\n",
    "y_predict = classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network with 52 inputs, 100 hidden nodes, and 2 outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200, activation='relu', input_dim=56))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 - 0s - loss: 0.6967 - accuracy: 0.5666 - 350ms/epoch - 4ms/step\n",
      "Epoch 2/100\n",
      "87/87 - 0s - loss: 0.6317 - accuracy: 0.6417 - 61ms/epoch - 699us/step\n",
      "Epoch 3/100\n",
      "87/87 - 0s - loss: 0.6015 - accuracy: 0.6835 - 63ms/epoch - 722us/step\n",
      "Epoch 4/100\n",
      "87/87 - 0s - loss: 0.5850 - accuracy: 0.6882 - 64ms/epoch - 734us/step\n",
      "Epoch 5/100\n",
      "87/87 - 0s - loss: 0.5569 - accuracy: 0.7191 - 69ms/epoch - 791us/step\n",
      "Epoch 6/100\n",
      "87/87 - 0s - loss: 0.5269 - accuracy: 0.7477 - 68ms/epoch - 779us/step\n",
      "Epoch 7/100\n",
      "87/87 - 0s - loss: 0.4870 - accuracy: 0.7684 - 69ms/epoch - 791us/step\n",
      "Epoch 8/100\n",
      "87/87 - 0s - loss: 0.4656 - accuracy: 0.7844 - 66ms/epoch - 757us/step\n",
      "Epoch 9/100\n",
      "87/87 - 0s - loss: 0.4186 - accuracy: 0.8229 - 72ms/epoch - 825us/step\n",
      "Epoch 10/100\n",
      "87/87 - 0s - loss: 0.3825 - accuracy: 0.8490 - 78ms/epoch - 892us/step\n",
      "Epoch 11/100\n",
      "87/87 - 0s - loss: 0.3470 - accuracy: 0.8603 - 62ms/epoch - 711us/step\n",
      "Epoch 12/100\n",
      "87/87 - 0s - loss: 0.3106 - accuracy: 0.8817 - 63ms/epoch - 722us/step\n",
      "Epoch 13/100\n",
      "87/87 - 0s - loss: 0.2801 - accuracy: 0.8944 - 107ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "87/87 - 0s - loss: 0.2470 - accuracy: 0.9191 - 115ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "87/87 - 0s - loss: 0.2193 - accuracy: 0.9292 - 94ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "87/87 - 0s - loss: 0.2031 - accuracy: 0.9423 - 71ms/epoch - 814us/step\n",
      "Epoch 17/100\n",
      "87/87 - 0s - loss: 0.1497 - accuracy: 0.9688 - 61ms/epoch - 699us/step\n",
      "Epoch 18/100\n",
      "87/87 - 0s - loss: 0.1260 - accuracy: 0.9764 - 63ms/epoch - 722us/step\n",
      "Epoch 19/100\n",
      "87/87 - 0s - loss: 0.1061 - accuracy: 0.9811 - 61ms/epoch - 699us/step\n",
      "Epoch 20/100\n",
      "87/87 - 0s - loss: 0.0834 - accuracy: 0.9917 - 66ms/epoch - 757us/step\n",
      "Epoch 21/100\n",
      "87/87 - 0s - loss: 0.0654 - accuracy: 0.9971 - 71ms/epoch - 814us/step\n",
      "Epoch 22/100\n",
      "87/87 - 0s - loss: 0.0640 - accuracy: 0.9906 - 70ms/epoch - 802us/step\n",
      "Epoch 23/100\n",
      "87/87 - 0s - loss: 0.0519 - accuracy: 0.9949 - 64ms/epoch - 734us/step\n",
      "Epoch 24/100\n",
      "87/87 - 0s - loss: 0.0422 - accuracy: 0.9964 - 94ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "87/87 - 0s - loss: 0.0376 - accuracy: 0.9967 - 78ms/epoch - 894us/step\n",
      "Epoch 26/100\n",
      "87/87 - 0s - loss: 0.0262 - accuracy: 0.9993 - 62ms/epoch - 711us/step\n",
      "Epoch 27/100\n",
      "87/87 - 0s - loss: 0.0222 - accuracy: 1.0000 - 64ms/epoch - 734us/step\n",
      "Epoch 28/100\n",
      "87/87 - 0s - loss: 0.0164 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 29/100\n",
      "87/87 - 0s - loss: 0.0145 - accuracy: 1.0000 - 63ms/epoch - 722us/step\n",
      "Epoch 30/100\n",
      "87/87 - 0s - loss: 0.0122 - accuracy: 1.0000 - 64ms/epoch - 734us/step\n",
      "Epoch 31/100\n",
      "87/87 - 0s - loss: 0.0106 - accuracy: 1.0000 - 79ms/epoch - 911us/step\n",
      "Epoch 32/100\n",
      "87/87 - 0s - loss: 0.0088 - accuracy: 1.0000 - 71ms/epoch - 814us/step\n",
      "Epoch 33/100\n",
      "87/87 - 0s - loss: 0.0077 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 34/100\n",
      "87/87 - 0s - loss: 0.0071 - accuracy: 1.0000 - 59ms/epoch - 676us/step\n",
      "Epoch 35/100\n",
      "87/87 - 0s - loss: 0.0078 - accuracy: 1.0000 - 59ms/epoch - 676us/step\n",
      "Epoch 36/100\n",
      "87/87 - 0s - loss: 0.0060 - accuracy: 1.0000 - 59ms/epoch - 676us/step\n",
      "Epoch 37/100\n",
      "87/87 - 0s - loss: 0.0052 - accuracy: 1.0000 - 59ms/epoch - 676us/step\n",
      "Epoch 38/100\n",
      "87/87 - 0s - loss: 0.0046 - accuracy: 1.0000 - 75ms/epoch - 860us/step\n",
      "Epoch 39/100\n",
      "87/87 - 0s - loss: 0.0041 - accuracy: 1.0000 - 62ms/epoch - 710us/step\n",
      "Epoch 40/100\n",
      "87/87 - 0s - loss: 0.0036 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 41/100\n",
      "87/87 - 0s - loss: 0.0033 - accuracy: 1.0000 - 59ms/epoch - 676us/step\n",
      "Epoch 42/100\n",
      "87/87 - 0s - loss: 0.0031 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 43/100\n",
      "87/87 - 0s - loss: 0.0028 - accuracy: 1.0000 - 58ms/epoch - 665us/step\n",
      "Epoch 44/100\n",
      "87/87 - 0s - loss: 0.0026 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 45/100\n",
      "87/87 - 0s - loss: 0.0024 - accuracy: 1.0000 - 74ms/epoch - 848us/step\n",
      "Epoch 46/100\n",
      "87/87 - 0s - loss: 0.0022 - accuracy: 1.0000 - 67ms/epoch - 768us/step\n",
      "Epoch 47/100\n",
      "87/87 - 0s - loss: 0.0020 - accuracy: 1.0000 - 62ms/epoch - 711us/step\n",
      "Epoch 48/100\n",
      "87/87 - 0s - loss: 0.0019 - accuracy: 1.0000 - 58ms/epoch - 665us/step\n",
      "Epoch 49/100\n",
      "87/87 - 0s - loss: 0.0017 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 50/100\n",
      "87/87 - 0s - loss: 0.0016 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 51/100\n",
      "87/87 - 0s - loss: 0.0015 - accuracy: 1.0000 - 58ms/epoch - 665us/step\n",
      "Epoch 52/100\n",
      "87/87 - 0s - loss: 0.0013 - accuracy: 1.0000 - 58ms/epoch - 665us/step\n",
      "Epoch 53/100\n",
      "87/87 - 0s - loss: 0.0012 - accuracy: 1.0000 - 65ms/epoch - 745us/step\n",
      "Epoch 54/100\n",
      "87/87 - 0s - loss: 0.0012 - accuracy: 1.0000 - 79ms/epoch - 906us/step\n",
      "Epoch 55/100\n",
      "87/87 - 0s - loss: 0.0011 - accuracy: 1.0000 - 62ms/epoch - 711us/step\n",
      "Epoch 56/100\n",
      "87/87 - 0s - loss: 0.0010 - accuracy: 1.0000 - 59ms/epoch - 676us/step\n",
      "Epoch 57/100\n",
      "87/87 - 0s - loss: 9.4142e-04 - accuracy: 1.0000 - 57ms/epoch - 653us/step\n",
      "Epoch 58/100\n",
      "87/87 - 0s - loss: 8.8868e-04 - accuracy: 1.0000 - 65ms/epoch - 745us/step\n",
      "Epoch 59/100\n",
      "87/87 - 0s - loss: 8.2342e-04 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 60/100\n",
      "87/87 - 0s - loss: 7.7246e-04 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 61/100\n",
      "87/87 - 0s - loss: 7.2601e-04 - accuracy: 1.0000 - 64ms/epoch - 734us/step\n",
      "Epoch 62/100\n",
      "87/87 - 0s - loss: 6.8086e-04 - accuracy: 1.0000 - 64ms/epoch - 734us/step\n",
      "Epoch 63/100\n",
      "87/87 - 0s - loss: 6.2310e-04 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 64/100\n",
      "87/87 - 0s - loss: 6.0980e-04 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 65/100\n",
      "87/87 - 0s - loss: 5.5999e-04 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 66/100\n",
      "87/87 - 0s - loss: 5.1529e-04 - accuracy: 1.0000 - 66ms/epoch - 757us/step\n",
      "Epoch 67/100\n",
      "87/87 - 0s - loss: 5.3297e-04 - accuracy: 1.0000 - 68ms/epoch - 780us/step\n",
      "Epoch 68/100\n",
      "87/87 - 0s - loss: 4.6639e-04 - accuracy: 1.0000 - 71ms/epoch - 814us/step\n",
      "Epoch 69/100\n",
      "87/87 - 0s - loss: 4.3929e-04 - accuracy: 1.0000 - 72ms/epoch - 825us/step\n",
      "Epoch 70/100\n",
      "87/87 - 0s - loss: 4.1974e-04 - accuracy: 1.0000 - 64ms/epoch - 734us/step\n",
      "Epoch 71/100\n",
      "87/87 - 0s - loss: 3.8055e-04 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 72/100\n",
      "87/87 - 0s - loss: 3.5651e-04 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 73/100\n",
      "87/87 - 0s - loss: 3.3679e-04 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 74/100\n",
      "87/87 - 0s - loss: 3.1824e-04 - accuracy: 1.0000 - 77ms/epoch - 883us/step\n",
      "Epoch 75/100\n",
      "87/87 - 0s - loss: 3.0307e-04 - accuracy: 1.0000 - 69ms/epoch - 791us/step\n",
      "Epoch 76/100\n",
      "87/87 - 0s - loss: 2.8133e-04 - accuracy: 1.0000 - 65ms/epoch - 745us/step\n",
      "Epoch 77/100\n",
      "87/87 - 0s - loss: 2.6516e-04 - accuracy: 1.0000 - 63ms/epoch - 722us/step\n",
      "Epoch 78/100\n",
      "87/87 - 0s - loss: 2.5784e-04 - accuracy: 1.0000 - 59ms/epoch - 676us/step\n",
      "Epoch 79/100\n",
      "87/87 - 0s - loss: 2.4296e-04 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 80/100\n",
      "87/87 - 0s - loss: 2.2466e-04 - accuracy: 1.0000 - 65ms/epoch - 745us/step\n",
      "Epoch 81/100\n",
      "87/87 - 0s - loss: 2.1019e-04 - accuracy: 1.0000 - 69ms/epoch - 791us/step\n",
      "Epoch 82/100\n",
      "87/87 - 0s - loss: 2.0136e-04 - accuracy: 1.0000 - 71ms/epoch - 814us/step\n",
      "Epoch 83/100\n",
      "87/87 - 0s - loss: 1.8746e-04 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 84/100\n",
      "87/87 - 0s - loss: 1.7824e-04 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 85/100\n",
      "87/87 - 0s - loss: 1.6836e-04 - accuracy: 1.0000 - 72ms/epoch - 825us/step\n",
      "Epoch 86/100\n",
      "87/87 - 0s - loss: 1.6450e-04 - accuracy: 1.0000 - 66ms/epoch - 757us/step\n",
      "Epoch 87/100\n",
      "87/87 - 0s - loss: 1.5186e-04 - accuracy: 1.0000 - 62ms/epoch - 711us/step\n",
      "Epoch 88/100\n",
      "87/87 - 0s - loss: 1.4027e-04 - accuracy: 1.0000 - 64ms/epoch - 734us/step\n",
      "Epoch 89/100\n",
      "87/87 - 0s - loss: 1.3472e-04 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 90/100\n",
      "87/87 - 0s - loss: 1.2518e-04 - accuracy: 1.0000 - 60ms/epoch - 688us/step\n",
      "Epoch 91/100\n",
      "87/87 - 0s - loss: 1.2035e-04 - accuracy: 1.0000 - 66ms/epoch - 757us/step\n",
      "Epoch 92/100\n",
      "87/87 - 0s - loss: 1.1212e-04 - accuracy: 1.0000 - 87ms/epoch - 997us/step\n",
      "Epoch 93/100\n",
      "87/87 - 0s - loss: 1.0836e-04 - accuracy: 1.0000 - 70ms/epoch - 802us/step\n",
      "Epoch 94/100\n",
      "87/87 - 0s - loss: 1.0273e-04 - accuracy: 1.0000 - 69ms/epoch - 791us/step\n",
      "Epoch 95/100\n",
      "87/87 - 0s - loss: 9.5624e-05 - accuracy: 1.0000 - 68ms/epoch - 780us/step\n",
      "Epoch 96/100\n",
      "87/87 - 0s - loss: 8.9897e-05 - accuracy: 1.0000 - 62ms/epoch - 711us/step\n",
      "Epoch 97/100\n",
      "87/87 - 0s - loss: 8.5843e-05 - accuracy: 1.0000 - 65ms/epoch - 745us/step\n",
      "Epoch 98/100\n",
      "87/87 - 0s - loss: 8.8794e-05 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 99/100\n",
      "87/87 - 0s - loss: 7.7631e-05 - accuracy: 1.0000 - 61ms/epoch - 699us/step\n",
      "Epoch 100/100\n",
      "87/87 - 0s - loss: 7.3338e-05 - accuracy: 1.0000 - 98ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23749b7e488>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 3.5890 - accuracy: 0.5441 - 134ms/epoch - 5ms/step\n",
      "Normal Neural Network - Loss: 3.589019298553467, Accuracy: 0.5440696477890015\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5843307943416758"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the data\n",
    "rf = rf.fit(X_train_scaled, y_train_categorical)\n",
    "rf.score(X_test_scaled, y_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model has the highest accuracy (63%), therefore this will be used to create our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_current_lose_streak: -0.033738280945557315\n",
      "B_current_win_streak: -0.17329752561543224\n",
      "B_draw: -0.07178418334873976\n",
      "B_avg_SIG_STR_landed: -0.09089332896520412\n",
      "B_avg_SIG_STR_pct: 0.00014537159396095766\n",
      "B_avg_SUB_ATT: 0.00031710546946651686\n",
      "B_avg_TD_landed: -0.16775726038956906\n",
      "B_avg_TD_pct: 0.017127293820240155\n",
      "B_longest_win_streak: 0.06488177840218715\n",
      "B_losses: 0.02936409688754114\n",
      "B_total_rounds_fought: 0.2656772352835206\n",
      "B_total_title_bouts: 0.02020472122088414\n",
      "B_win_by_Decision_Majority: 0.034347060963194606\n",
      "B_win_by_Decision_Split: 0.11104575858937181\n",
      "B_win_by_Decision_Unanimous: -0.04380777845538955\n",
      "B_win_by_KO/TKO: 0.03236299465864947\n",
      "B_win_by_Submission: 0.034600487044657194\n",
      "B_win_by_TKO_Doctor_Stoppage: 0.06357166892872526\n",
      "B_wins: -0.2602479021675643\n",
      "B_Height_cms: 0.07964470621063607\n",
      "B_Reach_cms: -0.2064340496888729\n",
      "R_current_lose_streak: -0.0344008806609688\n",
      "R_current_win_streak: 0.045833187760602835\n",
      "R_draw: 0.037348958092008964\n",
      "R_avg_SIG_STR_landed: 0.04688388213366475\n",
      "R_avg_SIG_STR_pct: 0.03846834584205609\n",
      "R_avg_SUB_ATT: -0.0464678469691534\n",
      "R_avg_TD_landed: 0.12466776443506061\n",
      "R_avg_TD_pct: 0.025785766322490876\n",
      "R_longest_win_streak: 0.07095665751244425\n",
      "R_losses: -0.10481011383842187\n",
      "R_total_rounds_fought: 0.19685390074313\n",
      "R_total_title_bouts: 0.06302228459912138\n",
      "R_win_by_Decision_Majority: -0.09354766166899549\n",
      "R_win_by_Decision_Split: -0.21970326680608487\n",
      "R_win_by_Decision_Unanimous: -0.10816778175230782\n",
      "R_win_by_KO/TKO: -0.05379325746968941\n",
      "R_win_by_Submission: -0.0818028156185977\n",
      "R_win_by_TKO_Doctor_Stoppage: -0.06849547840104844\n",
      "R_wins: 0.148404170955321\n",
      "R_Height_cms: -0.1747412027232484\n",
      "R_Reach_cms: 0.22852927679893487\n",
      "R_age: -0.28085803041836327\n",
      "B_age: 0.2622536615232599\n",
      "B_winratio: 0.009333711983802227\n",
      "R_winratio: 0.03870222454743498\n",
      "B_totalfights: -0.1690318550215665\n",
      "R_totalfights: 0.0608268667294864\n",
      "B_Stance_Open Stance: -0.12492792233360611\n",
      "B_Stance_Orthodox: 0.02918029833453274\n",
      "B_Stance_Southpaw: -0.013580741704085056\n",
      "B_Stance_Switch: -0.0228281449432647\n",
      "R_Stance_Open Stance: -0.21173928758917626\n",
      "R_Stance_Orthodox: -0.024448794702488705\n",
      "R_Stance_Southpaw: 0.043844892884373404\n",
      "R_Stance_Switch: -0.000922001921904211\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get importance\n",
    "importance = classifier.coef_[0]\n",
    "\n",
    "# Get features\n",
    "features = X.columns\n",
    "\n",
    "# summarize feature importance\n",
    "feature_count = 0\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "\tprint(f\"{features[feature_count]}: {v}\")\n",
    "\tfeature_count += 1\n",
    "\n",
    "pyplot.bar(features,importance)\n",
    "\n",
    "features_df = pd.DataFrame(importance, features)\n",
    "features_df.to_csv(\"resources/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ml_models/features.sav']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model \n",
    "import joblib \n",
    "\n",
    "joblib.dump(classifier, \"ml_models/model.sav\")\n",
    "joblib.dump(X_scaler, \"ml_models/x_scaler.sav\")\n",
    "joblib.dump(label_encoder, \"ml_models/encoder.sav\")\n",
    "joblib.dump(features, \"ml_models/features.sav\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce35a52ba9f165f93cf202864f27973ca61cb25b12d1f17d8290329beab40354"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
